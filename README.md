# B142_Data_Integration
In this report we provide an overview of the complete process involved in investigating large-scale datasets, focusing on the selection, preprocessing, integration, and analysis of data using advanced tools for big data. The major purpose of this study was to employ the Hadoop MapReduce and Apache Spark to effectively manage and process large amounts of data, ultimately obtaining valuable insights that can lead to informed decision-making.

**Origional Dataset Files**
annex1
annex2
annex3
annex4

**Hadoop Script Files**
Mapper.py
Reducer.py

**Hapdoop Output Results**
All files which name contain spark_processed
